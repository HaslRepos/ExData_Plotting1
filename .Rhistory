apply(a,dims=2,mean)
?apply
rowMeans(a, dims=2)
str(mapply)
noise<-function(n, mean, sd) {}
noise<-function(n, mean, sd) {
rnorm(n,mean,sd)
}
noise(5,1,2)
noise(1:5, 1:5, 2)
mapply(noise, 1:5,1:5,2)
x<-c(rnorm(10), runif(10), rnorm(10,1))
f<-gl(3,10)
f
x
tapply(x, f, mean)
f<-gl(10,3)
tapply(x, f, mean)
f<-gl(3,10)
tapply(x, f, mean, simplify=FALSE)
tapply(x, f, range)
split(x,f)
lapply(split(x,f),mean)
tapply(x, f, mean)
sapply(split(x,f),mean)
library(datasets)
head(airquality)
s<-split(airquality, airquality$Month)
s
lapply(s, function(x), colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
head(airquality)
sapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")], na.rm=TRUE))
x<-rnorm(10)
f1<-gl(2,5)
f2<-gl(5,2)
f1
f2
interaction(f1,f2)
str(split(x, list(f1,f2)))
log(-1)
sqrt(-4)
traceback
mean(x)
mean(z)
traceback()
lm(z-w)
traceback()
debug(lm)
lm(z - w)
options(error=recover)
read.csv("nosuchfile")
clear()
clear()
swirl()
library(swirl)
swirl()
head(flags)
dim(flags)
viewinfo()
class(flags)
cls_list<-lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect<-sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors<-flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag<-shapesflags[,19:23]
flag_shapes<-flags[,19:23]
lapply(flag_shapes, range)
shape_mat<-sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals<-lapply(flags, unique)
unique_vals
lapply(unique_vals, length)
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
0
q
e
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
library(datasets)
data("iris")
?iris
iris
tapply(iris$Species)
tapply(iris$Species, mean)
tapply(iris, iris$Species, mean)
tapply(iris, iris$Species, mean)
tapply(iris, iris$Species)
tapply(iris$Sepal.Length, iris$Species)
tapply(iris$Sepal.Length, iris$Species, mean)
colMeans(iris)
?apply
apply(iris[1:4],2,mean)
apply(iris,2,mean)
library(datasets)
data(mtcars)
?mtcars
sapply(split(mtcars$mpg, mtcars$cyl, mean))
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(mtcars, cyl, mean)
split(mtcars, mtcars$cyl)
split(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$cyl, mtcars$mpg), mean)
with(mtc)
with(mtcars, tapply(mpg, cyl, mean))
sapply(split(mtcars$cyl, mtcars$mpg), mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
lapply(mtcars, mean)
sapply(split(mtcars$cyl, mtcars$hp), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
avg_hp<-sapply(split(mtcars$hp, mtcars$cyl), mean)
avg_hp
class(avg_hp)
avg_hp[3]-avg_hp[1]
debug(ls)
ls
library(makeVector)
load(makeVector.R)
source(makeVector.R)
source("makeVector.R")
vect1<-makeVector(c(1,3,5,7,9))
x vect1
vect1
vect1&get
cachemean(vect1)
vect1<-makeVector(c(2,4,6,8,10))
cachemean(vect1)
vect1<-makeVector(c(1,2,3,4,5))
cachemean(vect1)
vect1<-makeVector(c(1,3,5,7,9))
cachemean(vect1)
setwd("~/Documents/Coursera")
fileUrl<-""
download.file(fileUrl, destfile="", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="acs.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile="rest.xml", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="ACS2.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="file1.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile="file3.xml", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="file4.csv", method="curl")
file1<-read.table("file1.csv")
head(file1)
names
names(file1)
?read.table
file1<-read.table("file1.csv", skip=1)
names(file1)
file1<-read.table("file1.csv", skip=1, sep=",")
names(file1)
file1<-read.table("file1.csv", skip=1, sep=",", header=TRUE)
names(file1)
file1<-read.table("file1.csv", sep=",", header=TRUE)
names(file1)
class(file1)
sub1<-subset(file1, file1$VAL=="24")
str(sub1)
library(xlsx)
install.packages("xlsx")
library(xlsx)
library(rJava)
library(xlsx)
sudo R CMD javareconf
install.packages("rJava",type='source')
install.packages("rJava", type = "source")
library(xlsx)
library(rJava)
library(xlsx)
R CMD javareconf
library(rJava)
library(xlsx)
file3<-xmlTreeParse(file3.xml, useInternal=TRUE)
library(XML)
install.packages("xml")
install.packages("XML")
library(XML)
file3<-xmlTreeParse(file3.xml, useInternal=TRUE)
setwd("~/Documents/Coursera")
file3<-xmlTreeParse("file3.xml", useInternal=TRUE)
root3<-xmlRoot(file3)
names(root3)
root3([[1]])
root3[[1]]
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
file3<-xmlTreeParse(url, useInternal=TRUE)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
file3<-xmlTreeParse(fileUrl, useInternal=TRUE)
file3<-xmlTreeParse("file3.xml", useInternal=TRUE)
root3<-xmlRoot(file3)
xmlName(root3)
xpathSApply(root3,"//zipcode", xmlValue)
erg3<-xpathSApply(root3,"//zipcode", xmlValue)
class(erg3)
erg3[erg3=="21231"]
nrow(erg3[erg3=="21231"])
str(erg3[erg3=="21231"])
library(data.table)
install.packages("data.table")
library(data.table)
?data.table
fread("file4.csv")
DT<-fread("file4.csv")
mean(DT$pwgtp15, by=DT$SEX)
source(w1f4.R)
source("w1f4.R")
source("w1f4.R")
w1f4
source("w1f4.R")
source("w1f4.R")
mean_w1f4()
source("w1f4.R")
mean_w1f4()
class(DT)
names(DT)
mean(DT[DT$SEX==1,]$pwgtp15);mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15)
mean(DT[DT$SEX==1]$pwgtp15)
tapply(DT$pwgtp15,DT$SEX,mean)
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15, by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2]
mean(DT$pwgtp15, by=DT$SEX)
DT<-fread("file4.csv")
mean(DT$pwgtp15, by=DT$SEX)
mean(DT$pwgtp15)
names(DT)
class(DT)
mean(DT$pwgtp15)
source("w1f4.R")
mean_w1f4()
mean(DT$pwgtp15)
DT2<-fread("file4.csv")
mean(DT2$pwgtp15)
head(DT2)
str(DT2$pwgtp15)
mean(DT2$pwgtp15)
?mean
x<-mean(DT2$pwgtp15)
DT2<-fread("file4.csv")
library(data.table)
DT2<-fread("file4.csv")
mean(DT2$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15)
mean(DT2[DT2$SEX==1,]$pwgtp15)
ptm <- proc.time()
proc.time() - ptm
source("w1f4.R")
mean_f1f4()
source("w1f4.R")
?rowMeans
source("w1f4.R")
source("w1f4.R")
source("w1f4.R")
source("w1f4.R")
source("w1f4.R")
source("w1f4.R")
source("w1f4.R")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="file2.csv", method="curl")
fileUrl<-"http://biostat.jhsph.edu/~jleek/contact.html"
download.file(fileUrl, destfile="file4.html", method="curl")
install.packages("sqldf")
library(httr)
oauth_endpoints("github", key="2b87fb166958ee10e9da", secret="e3d30c31288bbeb0e7ccbd89ed97df6344e5defb")
oauth_endpoints("github")
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="e3d30c31288bbeb0e7ccbd89ed97df6344e5defb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="e3d30c31288bbeb0e7ccbd89ed97df6344e5defb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
stop_for_status(req)
oauth_endpoints("github")
myapp2 <- oauth_app("github", key="2b87fb166958ee10e9da", secret="e3d30c31288bbeb0e7ccbd89ed97df6344e5defb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp2)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="e3d30c31288bbeb0e7ccbd89ed97df6344e5defb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="d0919eb21701ad02961a9355c36f453ce8101b52")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="d0919eb21701ad02961a9355c36f453ce8101b52")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(httpuv)
myapp <- oauth_app("github", key="2b87fb166958ee10e9da", secret="d0919eb21701ad02961a9355c36f453ce8101b52")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="w3file1.html", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile="w3file2.html", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="w3file3.html", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile="w3file32.html", method="curl")
?history
swirl()
library(swirl)
ls()
rm(list=ls())
swirl()
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
dim()
dim(mydf)
head(mydf)
library(dplyr)
packageVersion(dplyr)
packageVersion("dplyr")
cran<- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(-(x:size))
select(cran, -(x:size))
select(cran, -(X:size))
fileter(cran, package=="swirl")
filter(cran, package=="swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country=="US"|country=="IN")
filter(cran, size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran, ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes=mean(size))
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran, package)
by_package
summarize(cran, avg_bytes=mean(size))
summarize(cran, mean(size))
summarize(by_package, mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum, count>679)
top_counts
view(top_counts)
View(top_counts)
top_counts_sorted<-arrange(top_counts, desc(count()))
top_counts_sorted<-arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted<-arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="w4file1.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(fileUrl, destfile="w4file1.pdf", method="curl", mode="wb")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="w4file2.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="w4file31.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile="w4file32.csv", method="curl")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile="w4assign.pdf", method="curl", mode="wb")
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
month(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 21, minutes = 45, seconds = 55)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
depart nyc + days(2)
depart <- nyc + days(2)
depart
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone="Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
setwd("~/Documents/Coursera/eda/ExData_Plotting1")
?read.table
read.table("./houshold_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
read.table("./household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
read.table("./household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
read.table("household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
read.table("./ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
read.table("../household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?")
df <- read.table("../household_power_consumption.txt", sep = ";", header = TRUE, na.strings = "?",skip=grep("02/01/2007", readLines("../household_power_consumption.txt")),nrows=365)
